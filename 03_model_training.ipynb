{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155d2411",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model training - base model\n",
    "# tracking with mlflow\n",
    "# Import the specific regression models from scikit-learn\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "import os\n",
    "from mlflow.models import infer_signature\n",
    "import pandas as pd\n",
    "#from urlib.parse import urlparse\n",
    "import mlflow\n",
    "#from sklearn.compose import TransformedTargetRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from dotenv import load_dotenv\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, FunctionTransformer\n",
    "from sklearn.compose import make_column_selector, make_column_transformer\n",
    "import numpy as np\n",
    "import mlflow.sklearn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "46637664",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b86beaea",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['MLFLOW_TRACKING_URI']= os.getenv(\"MLFLOW_TRACKING_URI\")\n",
    "os.environ['MLFLOW_TRACKING_USERNAME']= os.getenv(\"MLFLOW_TRACKING_USERNAME\")\n",
    "os.environ[\"MLFLOW_TRACKING_PASSWORD\"]= os.getenv(\"MLFLOW_TRACKING_PASSWORD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "07bce6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing pipeline \n",
    "\n",
    "# defining numerical and categorical columns\n",
    "\n",
    "# preprocessing pipeline the numerical features that is all the features in the dataset\n",
    "# defining pipeline\n",
    "num_pipeline = make_pipeline(SimpleImputer(strategy=\"median\"),\n",
    "                                     StandardScaler())\n",
    "# pipeline for  the log transformation to handle skew features\n",
    "log_pipeline = make_pipeline(\n",
    "    SimpleImputer(strategy=\"median\"),\n",
    "    FunctionTransformer(np.log, feature_names_out=\"one-to-one\"),\n",
    "    StandardScaler())\n",
    "\n",
    "\n",
    "\n",
    "# building the preprocessing pipeline\n",
    "preprocessing = make_column_transformer(\n",
    "    (num_pipeline, make_column_selector(dtype_include=np.number)),\n",
    "    (log_pipeline, make_column_selector(dtype_include=np.number)),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6dc3d253",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['calories', 'weight_(kg)', 'lean_mass_kg', 'bmi', 'fat_percentage',\n",
       "       'protein_per_kg'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data from the artifact folder version 1- before it was preprocessed\n",
    "# we will run it through a preprocessin pipeline\n",
    "\n",
    "data = pd.read_csv(\"../artifacts/ml_training_data.csv\")\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c7171c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train test set\n",
    "X_train = data.drop(columns='calories')\n",
    "y_train = data.calories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d0bc2cd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['weight_(kg)', 'lean_mass_kg', 'bmi', 'fat_percentage',\n",
       "       'protein_per_kg'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9bd58da8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "calories",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "2c7a16e2-6528-4a90-b8fc-541690a55b82",
       "rows": [
        [
         "0",
         "1967.0"
        ],
        [
         "1",
         "1508.0"
        ],
        [
         "2",
         "2181.0"
        ],
        [
         "3",
         "2372.0"
        ],
        [
         "4",
         "1875.0"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 5
       }
      },
      "text/plain": [
       "0    1967.0\n",
       "1    1508.0\n",
       "2    2181.0\n",
       "3    2372.0\n",
       "4    1875.0\n",
       "Name: calories, dtype: float64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5915a2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Instantiate each model\n",
    "\n",
    "models = {\n",
    "    \"RandomForest\": RandomForestRegressor(random_state=42),\n",
    "    \"XGBoost\": XGBRegressor(random_state=42, n_estimators=500, learning_rate=0.05),\n",
    "    \"LightGBM\": LGBMRegressor(random_state=42, n_estimators=500, learning_rate=0.05),\n",
    "    \"LinearRegression\": LinearRegression(),\n",
    "    \"Ridge_Model\": Ridge(alpha=1.0, random_state=42),\n",
    "    \"Lasso_Model\": Lasso(alpha=0.1, random_state=42),\n",
    "    \"Elastic_Net_Model\": ElasticNet(alpha=0.1, l1_ratio=0.5, random_state=42),\n",
    "    \"KNN_Model\": KNeighborsRegressor(n_neighbors=5),\n",
    "    \"SVM_Model\": SVR(kernel='rbf'),\n",
    "    \"Decision_Tree\": DecisionTreeRegressor()\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db3ad36f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting RandomForest...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/18 16:15:29 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting XGBoost...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/18 16:57:55 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting LightGBM...\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002121 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2550\n",
      "[LightGBM] [Info] Number of data points in the train set: 16000, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\AbiolaLawani\\miniconda3\\envs\\mlops\\lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "2025/10/18 16:58:54 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting LinearRegression...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/18 16:59:33 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting Ridge_Model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/18 16:59:45 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting Lasso_Model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/18 16:59:58 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting Elastic_Net_Model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/18 17:00:11 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting KNN_Model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/18 17:00:24 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting SVM_Model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/18 17:01:46 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting Decision_Tree...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/18 17:02:15 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   train_RMSE_RandomForest  ...  train_R2_Decision_Tree\n",
      "RandomForest                     40.850228  ...                     NaN\n",
      "XGBoost                                NaN  ...                     NaN\n",
      "LightGBM                               NaN  ...                     NaN\n",
      "LinearRegression                       NaN  ...                     NaN\n",
      "Ridge_Model                            NaN  ...                     NaN\n",
      "Lasso_Model                            NaN  ...                     NaN\n",
      "Elastic_Net_Model                      NaN  ...                     NaN\n",
      "KNN_Model                              NaN  ...                     NaN\n",
      "SVM_Model                              NaN  ...                     NaN\n",
      "Decision_Tree                          NaN  ...                     1.0\n",
      "\n",
      "[10 rows x 30 columns]\n",
      "🏃 View run debonair-calf-404 at: https://dagshub.com/abiolaks/TrulyFitAI.mlflow/#/experiments/0/runs/a3bed2018c0449689d80bbd44d0b9537\n",
      "🧪 View experiment at: https://dagshub.com/abiolaks/TrulyFitAI.mlflow/#/experiments/0\n"
     ]
    }
   ],
   "source": [
    "# training scipt\n",
    "# tracking url\n",
    "#os.environ['MLFLOW_TRACKING_URI']=\"https://dagshub.com/abiolaks/TrulyFitAI.mlflow\"\n",
    "#os.environ['MLFLOW_TRACKING_USERNAME']=\"abiolaks\"\n",
    "#os.environ[\"MLFLOW_TRACKING_PASSWORD\"]=\"3d5376f582499caded3df9ed9ac74941da8b0128\"\n",
    "\n",
    "mlflow.set_tracking_uri(\"https://dagshub.com/abiolaks/TrulyFitAI.mlflow\")\n",
    "with mlflow.start_run():\n",
    "    signature=infer_signature(X_train,y_train)\n",
    "    pipelines = {} # A dictionary to store the final pipelines\n",
    "    results = {}\n",
    "    \n",
    "    # Capture a sample input for the model signature\n",
    "    # This is a single row or a small batch from the training data\n",
    "    input_example = X_train.iloc[[0]]\n",
    "\n",
    "    for name, model in models.items():\n",
    "        # Wrap the current model with TransformedTargetRegressor to handle the target (y) scaling\n",
    "        #wrapped_model = TransformedTargetRegressor(\n",
    "           # regressor=model,\n",
    "            #transformer=StandardScaler()\n",
    "       # )\n",
    "        \n",
    "        # Create the full pipeline: features are scaled, then the wrapped model is applied\n",
    "        full_pipeline = make_pipeline(preprocessing, model)\n",
    "        \n",
    "        # Store the complete pipeline for the current model\n",
    "        pipelines[name] = full_pipeline\n",
    "        \n",
    "        # Fit the complete pipeline\n",
    "        print(f\"Fitting {name}...\")\n",
    "        full_pipeline.fit(X_train, y_train)\n",
    "        preds = full_pipeline.predict(X_train)\n",
    "        \n",
    "        \n",
    "         ## Log metrics \\\n",
    "        # Create the dictionary of metrics\n",
    "        metrics = {\n",
    "            f\"train_RMSE_{name}\": np.sqrt(mean_squared_error(y_train, preds)),\n",
    "            f\"train_MAE_{name}\": mean_absolute_error(y_train, preds),\n",
    "            f\"train_R2_{name}\": r2_score(y_train, preds)\n",
    "        }\n",
    "        \n",
    "        # Store metrics in the results dictionary for later\n",
    "        results[name] = metrics\n",
    "        \n",
    "        # Log all metrics at once to MLflow with a single function call\n",
    "        mlflow.log_metrics(metrics)\n",
    "        \n",
    "        # Log the trained pipeline model\n",
    "        mlflow.sklearn.log_model(\n",
    "            sk_model=full_pipeline,\n",
    "            artifact_path=name,\n",
    "            input_example=input_example\n",
    "        )\n",
    "        \n",
    "\n",
    "    results_df = pd.DataFrame(results).T\n",
    "    print(results_df)\n",
    "\n",
    "# Now you can use the `pipelines` dictionary to make predictions\n",
    "# For example:\n",
    "# predictions = pipelines['Linear Regression'].predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76662f94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e05ac366",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlops",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
